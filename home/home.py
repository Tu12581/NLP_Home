#!/usr/bin/env python3
import pandas as pd
import json
import re
import jieba
import jieba.posseg as pseg
import numpy as np
from tqdm import tqdm
from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

"""TextFooleræ”»å‡»ç®—æ³•çš„ä¸¥æ ¼å¤ç°ç‰ˆæœ¬ã€‚
é€šè¿‡è¯çº§åŒä¹‰è¯æ›¿æ¢æ¥æ”»å‡»å¤§æ¨¡å‹åˆ†ç±»å™¨ã€‚
å…¶æ ¸å¿ƒé€»è¾‘æ˜¯è¯†åˆ«â€œé‡è¦è¯æ±‡â€ï¼Œåˆ©ç”¨ LLM ç”ŸæˆåŒä¹‰è¯ï¼Œ
é€šè¿‡è¯­ä¹‰ç›¸ä¼¼åº¦å’Œé»‘ç›’æ¨¡å‹æŸ¥è¯¢ç­›é€‰å‡ºèƒ½æˆåŠŸæ”¹å˜åˆ†ç±»ç»“æœçš„å¯¹æŠ—æ ·æœ¬ã€‚"""
# =================é…ç½®åŒºåŸŸ=================
INPUT_FILE = 'qwen_pred_train.csv'
OUTPUT_ADV_CSV = 'adversarial_textfooler_strict_results.csv'
OUTPUT_SUMMARY = 'adversarial_textfooler_strict_summary.json'

# æ¨¡å‹è®¾ç½®
ATTACKER_MODEL = "qwen3:4b"  # è´Ÿè´£ç”ŸæˆåŒä¹‰è¯
VICTIM_MODEL = "qwen3:4b"  # è´Ÿè´£è¢«æ”»å‡»

# é˜ˆå€¼è®¾ç½® (TextFooler è®ºæ–‡å‚æ•°å‚è€ƒ)
SEMANTIC_THRESHOLD = 0.7  # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼ epsilon
MAX_CANDIDATES = 5  # æ¯ä¸ªè¯å°è¯•å¤šå°‘ä¸ªåŒä¹‰è¯ k
MAX_TEST_SAMPLES = 50  # æµ‹è¯•æ ·æœ¬æ•°

# =================æ¨¡å‹åˆå§‹åŒ–=================
print("æ­£åœ¨åˆå§‹åŒ– LLM æ¨¡å‹...")
attacker_llm = ChatOllama(model=ATTACKER_MODEL, temperature=0.8)  # é«˜æ¸©åº¦å¢åŠ å¤šæ ·æ€§
victim_llm = ChatOllama(model=VICTIM_MODEL, temperature=0.0)  # é›¶æ¸©åº¦ä¿è¯ç¨³å®šæ€§

print("æ­£åœ¨åŠ è½½è¯­ä¹‰ç¼–ç å™¨ (Sentence-BERT)...")
# ä½¿ç”¨è½»é‡çº§ä¸­æ–‡æ¨¡å‹è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
# å¦‚æœä¸‹è½½æ…¢ï¼Œå¯ä»¥æ¢æˆ "paraphrase-multilingual-MiniLM-L12-v2" æˆ–å…¶ä»–æœ¬åœ°æ¨¡å‹
encoder = SentenceTransformer('shibing624/text2vec-base-chinese')


# =================æ ¸å¿ƒåŠŸèƒ½å‡½æ•°=================

def get_victim_prediction(text: str):
    """
    è·å–å—å®³è€…æ¨¡å‹çš„é¢„æµ‹ç»“æœ
    æ¨¡æ‹Ÿå…¬å¼ F_Y(X) çš„è¾“å‡º
    è¿”å›: (pred_label, raw_output)
    """
    prompt = (
        """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åè¯ˆéª—æ£€æµ‹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å…·ä½“çš„å¯¹è¯å†…å®¹ï¼Œåˆ¤æ–­è¯¥å¯¹è¯æ˜¯å¦å±äºè¯ˆéª—ç”µè¯ã€‚
è¾“å…¥å†…å®¹ï¼š{text}
è¦æ±‚ï¼š
1. å¦‚æœæ˜¯è¯ˆéª—å¯¹è¯ï¼Œè¯·è¾“å‡º 1ã€‚
2. å¦‚æœæ˜¯æ­£å¸¸å¯¹è¯ï¼Œè¯·è¾“å‡º 0ã€‚
3. ä¸éœ€è¦è¾“å‡ºä»»ä½•åˆ†æè¿‡ç¨‹ï¼Œä»…è¾“å‡ºæœ€ç»ˆçš„æ•°å­—åˆ†ç±»ç»“æœã€‚
"""
        f"å¯¹è¯ï¼š{text}"
    )
    try:
        msg = victim_llm.invoke([HumanMessage(content=prompt)])
        raw = msg.content.strip()
        match = re.search(r'\b[01]\b', raw)
        if match:
            return int(match.group()), raw
        return 0, raw  # é»˜è®¤å¤„ç†
    except Exception:
        return 0, "Error"


def get_semantic_similarity(text1, text2):
    """
    è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ (Cosine Similarity)
    å¯¹åº”å…¬å¼: Cosine(Enc(X), Enc(X_adv))
    """
    # ç¼–ç ä¸ºå‘é‡
    emb1 = encoder.encode([text1])
    emb2 = encoder.encode([text2])
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    score = cosine_similarity(emb1, emb2)[0][0]
    return score


def get_synonyms_from_llm(word, context):
    """
    æ­¥éª¤äºŒï¼šåŒä¹‰è¯æå– (Synonym Extraction)
    ä½¿ç”¨ LLM ä½œä¸ºåŠ¨æ€è¯å…¸
    """
    prompt = f"""
è¯·ä¸ºå¥å­ä¸­çš„è¯è¯­â€œ{word}â€æä¾›{MAX_CANDIDATES}ä¸ªä¸­æ–‡åŒä¹‰è¯ã€‚
åŸå¥ï¼š{context}
è¦æ±‚ï¼š
1. ä»…è¾“å‡ºä¸­æ–‡è¯æ±‡ã€‚
2. æ„æ€ç›¸è¿‘ï¼Œä½†å¯ä»¥æ˜¯ä¸åŒçš„è¡¨è¾¾æ–¹å¼ï¼ˆå¦‚å£è¯­åŒ–ã€æ­£å¼åŒ–ï¼‰ã€‚
3. è¾“å‡ºæ ¼å¼ä¸ºï¼šè¯1, è¯2, è¯3
4. ä¸è¦åŒ…å«åŸè¯ã€‚
"""
    try:
        msg = attacker_llm.invoke([HumanMessage(content=prompt)])
        content = msg.content.replace('\n', ',').replace('ï¼Œ', ',')
        candidates = [c.strip() for c in content.split(',') if c.strip()]
        # è¿‡æ»¤éä¸­æ–‡å’Œè¿‡é•¿çš„è¯
        candidates = [c for c in candidates if re.match(r'^[\u4e00-\u9fa5]+$', c) and c != word]
        return candidates[:MAX_CANDIDATES]
    except:
        return []


def attack_one_sample(text, true_label=1):
    """
    1. ç§»é™¤åŸºäºæ¨¡å‹çš„ Importance Rankingï¼Œæ”¹ç”¨åŸºäºè¯é•¿çš„å¯å‘å¼æ’åºã€‚
    2. é™åˆ¶æœ€å¤§å°è¯•ä¿®æ”¹çš„è¯æ•°é‡ (TOP_N_WORDS)ã€‚
    """
    # 0. åŸºçº¿æ£€æŸ¥
    # orig_pred, _ = get_victim_prediction(text)
    orig_pred = 1
    if orig_pred != true_label:
        return None

        # === æ­¥éª¤ä¸€ï¼šå¿«é€Ÿç­›é€‰å…³é”®è¯ (Heuristic Ranking) ===
    # ä¸å†è°ƒç”¨æ¨¡å‹é¢„æµ‹ï¼Œè€Œæ˜¯ç›´æ¥åˆ†æè¯æ€§åŠé•¿åº¦
    words_pos = list(pseg.cut(text))
    words = [w for w, p in words_pos]
    pos_tags = [p for w, p in words_pos]

    # ç­›é€‰ç­–ç•¥ï¼šåªæ”»å‡» åè¯(n) å’Œ åŠ¨è¯(v)
    candidates_indices = []
    for i, (w, tag) in enumerate(words_pos):
        if tag.startswith(('n', 'v')) and len(w) > 1:  # å¿½ç•¥å•å­—ï¼Œåªçœ‹åŒå­—ä»¥ä¸Šçš„è¯
            candidates_indices.append(i)

    # ã€æé€Ÿä¼˜åŒ–ã€‘æŒ‰è¯é•¿åº¦é™åºæ’åºï¼ˆå‡è®¾é•¿è¯åŒ…å«æ›´å¤šè¯­ä¹‰ä¿¡æ¯ï¼‰
    # ä¹‹å‰æ˜¯è°ƒç”¨æ¨¡å‹ç®—åˆ†ï¼Œç°åœ¨ç›´æ¥ len(words[i])
    candidates_indices.sort(key=lambda i: len(words[i]), reverse=True)

    # ã€æé€Ÿä¼˜åŒ–ã€‘åªå°è¯•æ”»å‡»å‰ 5 ä¸ªæœ€é‡è¦çš„è¯ï¼Œå¤ªé åçš„ä¸æµªè´¹æ—¶é—´
    TOP_N_WORDS = 5
    target_indices = candidates_indices[:TOP_N_WORDS]

    # === å¾ªç¯æ”»å‡» ===
    current_words = words.copy()
    current_text = "".join(current_words)
    is_success = False
    logs = []

    # éå†è¿™äº›â€œå«Œç–‘è¯â€
    for idx in target_indices:
        original_word = words[idx]
        original_pos = pos_tags[idx]

        # === æ­¥éª¤äºŒï¼šåŒä¹‰è¯æå– ===
        # å‡å°‘å€™é€‰æ•°é‡åˆ° 3
        candidates = get_synonyms_from_llm(original_word, current_text)[:3]

        for cand in candidates:
            # === æ­¥éª¤ä¸‰ï¼šçº¦æŸæ£€æŸ¥ ===
            # 3.1 ç®€å•è¯æ€§è¿‡æ»¤
            cand_pos_gen = list(pseg.cut(cand))
            if not cand_pos_gen: continue
            if original_pos[0] != cand_pos_gen[0].flag[0]: continue

            # æ„é€ å¯¹æŠ—æ ·æœ¬
            temp_words = current_words.copy()
            temp_words[idx] = cand
            temp_text = "".join(temp_words)

            # 3.2 è¯­ä¹‰ç›¸ä¼¼åº¦ (å¦‚æœå¤ªæ…¢ï¼Œå¯ä»¥æŠŠè¿™æ­¥ä¹Ÿæ³¨é‡Šæ‰ï¼Œä½†è¿™æ­¥æ˜¯è®ºæ–‡æ ¸å¿ƒï¼Œå»ºè®®ä¿ç•™)
            # ä¸ºäº†é€Ÿåº¦ï¼Œä½ å¯ä»¥æŠŠ SEMANTIC_THRESHOLD ç¨å¾®è°ƒä½ï¼Œæˆ–è€…å…ˆä¸æµ‹ç›¸ä¼¼åº¦ç›´æ¥æµ‹åˆ†ç±»
            sim_score = get_semantic_similarity(text, temp_text)
            if sim_score < 0.65:  # ç¨å¾®é™ä½é˜ˆå€¼
                continue

                # === æ”»å‡»åˆ¤å®š (æœ€è€—æ—¶çš„ä¸€æ­¥) ===
            adv_pred, _ = get_victim_prediction(temp_text)

            if adv_pred == 0:
                current_words[idx] = cand
                current_text = temp_text
                is_success = True
                logs.append(f"Success: {original_word}->{cand}")
                break  # æˆåŠŸéª—è¿‡ï¼Œè·³å‡ºå€™é€‰è¯å¾ªç¯

        if is_success:
            break  # æˆåŠŸéª—è¿‡ï¼Œè·³å‡ºå¥å­å¾ªç¯

    return {
        "original_text": text,
        "adversarial_text": current_text,
        "label": true_label,
        "final_pred": 0 if is_success else 1,
        "attack_success": is_success,
        "change_log": "; ".join(logs)
    }


# =================ä¸»ç¨‹åº=================
def main():
    try:
        df = pd.read_csv(INPUT_FILE)
    except FileNotFoundError:
        print(f"âŒ è¯·å…ˆè¿è¡Œ home3.py ç”Ÿæˆ {INPUT_FILE}")
        return

    # ç­›é€‰ç›®æ ‡ï¼šLabel=1 ä¸” Pred=1
    target_df = df[(df['label'] == 1) & (df['pred'] == 1)].head(MAX_TEST_SAMPLES)
    targets = target_df['text'].tolist()

    results = []
    success_count = 0

    print(f"ğŸš€ å¼€å§‹æ”»å‡» {len(targets)} ä¸ªæ ·æœ¬...")

    for text in tqdm(targets):
        res = attack_one_sample(text)
        if res:
            results.append(res)
            if res['attack_success']:
                success_count += 1

    # ä¿å­˜ç»“æœ
    res_df = pd.DataFrame(results)
    res_df.to_csv(OUTPUT_ADV_CSV, index=False, encoding='utf-8')

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    asr = success_count / len(results) if results else 0
    summary = {
        "method": "TextFooler (Strict Implementation)",
        "total_attacked": len(results),
        "success_count": success_count,
        "ASR (Attack Success Rate)": asr
    }

    with open(OUTPUT_SUMMARY, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print("\n" + "=" * 30)
    print(f"âœ… å®éªŒç»“æŸ")
    print(f"æ”»å‡»æˆåŠŸç‡ (ASR): {asr:.2%}")
    print(f"ç»“æœæ–‡ä»¶: {OUTPUT_ADV_CSV}")
    print("=" * 30)


if __name__ == "__main__":
    main()